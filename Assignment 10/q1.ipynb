{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e525150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f8033e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid activation function\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def one_hot_encode(y, num_classes):\n",
    "    \"\"\"Convert labels to one-hot encoding\"\"\"\n",
    "    encoded = np.zeros((y.size, num_classes))\n",
    "    encoded[np.arange(y.size), y] = 1\n",
    "    return encoded\n",
    "\n",
    "def softmax(z):\n",
    "    \"\"\"Softmax for multi-class classification\"\"\"\n",
    "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c4ae7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionScratch:\n",
    "    def __init__(self, lr=0.01, epochs=1000):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train using gradient descent\"\"\"\n",
    "        num_samples, num_features = X.shape\n",
    "        num_classes = len(np.unique(y))\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.weights = np.zeros((num_features, num_classes))\n",
    "        self.bias = np.zeros((1, num_classes))\n",
    "        \n",
    "        # One-hot encode labels\n",
    "        y_one_hot = one_hot_encode(y, num_classes)\n",
    "        \n",
    "        # Gradient Descent\n",
    "        for i in range(self.epochs):\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            y_pred = softmax(linear_model)\n",
    "            \n",
    "            # Gradients\n",
    "            dw = (1 / num_samples) * np.dot(X.T, (y_pred - y_one_hot))\n",
    "            db = (1 / num_samples) * np.sum(y_pred - y_one_hot, axis=0, keepdims=True)\n",
    "            \n",
    "            # Update\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                loss = -np.mean(np.sum(y_one_hot * np.log(y_pred + 1e-8), axis=1))\n",
    "                print(f\"Epoch {i+1}/{self.epochs}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict labels\"\"\"\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = softmax(linear_model)\n",
    "        return np.argmax(y_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a13a99ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred) / len(y_true)\n",
    "\n",
    "def precision_score(y_true, y_pred, num_classes):\n",
    "    precision = []\n",
    "    for c in range(num_classes):\n",
    "        tp = np.sum((y_pred == c) & (y_true == c))\n",
    "        fp = np.sum((y_pred == c) & (y_true != c))\n",
    "        precision.append(tp / (tp + fp + 1e-8))\n",
    "    return np.mean(precision)\n",
    "\n",
    "def recall_score(y_true, y_pred, num_classes):\n",
    "    recall = []\n",
    "    for c in range(num_classes):\n",
    "        tp = np.sum((y_pred == c) & (y_true == c))\n",
    "        fn = np.sum((y_pred != c) & (y_true == c))\n",
    "        recall.append(tp / (tp + fn + 1e-8))\n",
    "    return np.mean(recall)\n",
    "\n",
    "def f1_score(y_true, y_pred, num_classes):\n",
    "    prec = precision_score(y_true, y_pred, num_classes)\n",
    "    rec = recall_score(y_true, y_pred, num_classes)\n",
    "    return 2 * (prec * rec) / (prec + rec + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23f17ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_image(arr):\n",
    "    \"\"\"Convert a 784-length array to a 28x28 grayscale image\"\"\"\n",
    "    image = arr.reshape(28, 28)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba6de8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_show(array_784, model):\n",
    "    \"\"\"Takes array of 784 pixels + trained model â†’ shows image + predicted label\"\"\"\n",
    "    image = array_to_image(array_784)\n",
    "    pred = model.predict(array_784.reshape(1, -1))\n",
    "    print(f\"Predicted Label: {pred[0]}\")\n",
    "    return image, pred[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e977448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500, Loss: 0.6065\n",
      "Epoch 200/500, Loss: 0.4855\n",
      "Epoch 300/500, Loss: 0.4359\n",
      "Epoch 400/500, Loss: 0.4072\n",
      "Epoch 500/500, Loss: 0.3880\n",
      "\n",
      "Evaluation Metrics (on Validation Set):\n",
      "Accuracy:  0.8974\n",
      "Precision: 0.8963\n",
      "Recall:    0.8949\n",
      "F1 Score:  0.8956\n",
      "\n",
      "Sample Test Predictions: [2 0 9 9 3 7 0 3 0 3]\n",
      "\n",
      "Predictions saved to mnist_predictions.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.1254902 , 0.66666667, 0.76470588, 0.05882353, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.03529412,\n",
       "         0.68235294, 0.99215686, 0.74509804, 0.00784314, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.50980392,\n",
       "         0.99215686, 0.82352941, 0.2627451 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.33333333, 0.96862745,\n",
       "         0.95686275, 0.27058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.10196078, 0.86666667, 0.99607843,\n",
       "         0.44313725, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.69019608, 0.99607843, 0.82352941,\n",
       "         0.08235294, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.24313725, 0.94117647, 0.96862745, 0.27843137,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.71372549, 0.99215686, 0.59215686, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.11764706, 0.92941176, 0.99607843, 0.13333333, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.57647059, 0.99215686, 0.79215686, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.90196078, 0.99215686, 0.33333333, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.10196078,\n",
       "         0.9372549 , 0.95686275, 0.17254902, 0.        , 0.        ,\n",
       "         0.        , 0.26666667, 0.7254902 , 0.5254902 , 0.06666667,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.2745098 ,\n",
       "         0.99607843, 0.96078431, 0.17254902, 0.        , 0.        ,\n",
       "         0.55294118, 0.99607843, 0.99607843, 0.99607843, 0.77254902,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.2745098 ,\n",
       "         0.99215686, 0.99215686, 0.27058824, 0.05098039, 0.6745098 ,\n",
       "         0.59607843, 0.09019608, 0.59607843, 0.99215686, 0.91764706,\n",
       "         0.05098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.05098039,\n",
       "         0.91764706, 0.99215686, 0.27058824, 0.28235294, 0.30980392,\n",
       "         0.        , 0.        , 0.2745098 , 0.99215686, 0.91764706,\n",
       "         0.05098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.90196078, 0.99215686, 0.27058824, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.40784314, 0.99215686, 0.90196078,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.6745098 , 0.99607843, 0.36862745, 0.        , 0.        ,\n",
       "         0.        , 0.10196078, 1.        , 0.94509804, 0.2627451 ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.31372549, 0.95686275, 0.82745098, 0.06666667, 0.        ,\n",
       "         0.        , 0.43137255, 0.99607843, 0.54509804, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.78039216, 0.99215686, 0.78039216, 0.45490196,\n",
       "         0.61568627, 0.90980392, 0.70588235, 0.01568627, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.1254902 , 0.40392157, 0.8627451 , 0.99215686,\n",
       "         0.82745098, 0.40392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]),\n",
       " np.int64(6))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"Data/train.csv\")\n",
    "test = pd.read_csv(\"Data/test.csv\")\n",
    "\n",
    "# Train data has labels\n",
    "X = train.drop(columns=['label']).values / 255.0\n",
    "y = train['label'].values\n",
    "\n",
    "# Split training data (use part as validation set)\n",
    "split_ratio = 0.8\n",
    "split_idx = int(split_ratio * len(X))\n",
    "\n",
    "X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "y_train, y_val = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# Test data (no labels)\n",
    "X_test = test.values / 255.0\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegressionScratch(lr=0.1, epochs=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "acc = accuracy_score(y_val, y_val_pred)\n",
    "prec = precision_score(y_val, y_val_pred, num_classes)\n",
    "rec = recall_score(y_val, y_val_pred, num_classes)\n",
    "f1 = f1_score(y_val, y_val_pred, num_classes)\n",
    "\n",
    "print(\"\\nEvaluation Metrics (on Validation Set):\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "# Predict labels for test.csv (no ground truth)\n",
    "test_predictions = model.predict(X_test)\n",
    "print(\"\\nSample Test Predictions:\", test_predictions[:10])\n",
    "\n",
    "# Optional: Save results\n",
    "submission = pd.DataFrame({'ImageId': np.arange(1, len(test_predictions) + 1),\n",
    "                           'Label': test_predictions})\n",
    "submission.to_csv(\"mnist_predictions.csv\", index=False)\n",
    "print(\"\\nPredictions saved to mnist_predictions.csv\")\n",
    "\n",
    "# Test on one random image from validation set\n",
    "sample = X_val[5]\n",
    "predict_and_show(sample, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
