{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e525150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f8033e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid activation function\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def one_hot_encode(y, num_classes):\n",
    "    \"\"\"Convert labels to one-hot encoding\"\"\"\n",
    "    encoded = np.zeros((y.size, num_classes))\n",
    "    encoded[np.arange(y.size), y] = 1\n",
    "    return encoded\n",
    "\n",
    "def softmax(z):\n",
    "    \"\"\"Softmax for multi-class classification\"\"\"\n",
    "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c4ae7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionScratch:\n",
    "    def __init__(self, lr=0.01, epochs=1000):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train using gradient descent\"\"\"\n",
    "        num_samples, num_features = X.shape\n",
    "        num_classes = len(np.unique(y))\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.weights = np.zeros((num_features, num_classes))\n",
    "        self.bias = np.zeros((1, num_classes))\n",
    "        \n",
    "        # One-hot encode labels\n",
    "        y_one_hot = one_hot_encode(y, num_classes)\n",
    "        \n",
    "        # Gradient Descent\n",
    "        for i in range(self.epochs):\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            y_pred = softmax(linear_model)\n",
    "            \n",
    "            # Gradients\n",
    "            dw = (1 / num_samples) * np.dot(X.T, (y_pred - y_one_hot))\n",
    "            db = (1 / num_samples) * np.sum(y_pred - y_one_hot, axis=0, keepdims=True)\n",
    "            \n",
    "            # Update\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                loss = -np.mean(np.sum(y_one_hot * np.log(y_pred + 1e-8), axis=1))\n",
    "                print(f\"Epoch {i+1}/{self.epochs}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict labels\"\"\"\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = softmax(linear_model)\n",
    "        return np.argmax(y_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a13a99ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred) / len(y_true)\n",
    "\n",
    "def precision_score(y_true, y_pred, num_classes):\n",
    "    precision = []\n",
    "    for c in range(num_classes):\n",
    "        tp = np.sum((y_pred == c) & (y_true == c))\n",
    "        fp = np.sum((y_pred == c) & (y_true != c))\n",
    "        precision.append(tp / (tp + fp + 1e-8))\n",
    "    return np.mean(precision)\n",
    "\n",
    "def recall_score(y_true, y_pred, num_classes):\n",
    "    recall = []\n",
    "    for c in range(num_classes):\n",
    "        tp = np.sum((y_pred == c) & (y_true == c))\n",
    "        fn = np.sum((y_pred != c) & (y_true == c))\n",
    "        recall.append(tp / (tp + fn + 1e-8))\n",
    "    return np.mean(recall)\n",
    "\n",
    "def f1_score(y_true, y_pred, num_classes):\n",
    "    prec = precision_score(y_true, y_pred, num_classes)\n",
    "    rec = recall_score(y_true, y_pred, num_classes)\n",
    "    return 2 * (prec * rec) / (prec + rec + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23f17ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_image(arr):\n",
    "    \"\"\"Convert a 784-length array to a 28x28 grayscale image\"\"\"\n",
    "    image = arr.reshape(28, 28)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba6de8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_show(array_784, model):\n",
    "    \"\"\"Takes array of 784 pixels + trained model â†’ shows image + predicted label\"\"\"\n",
    "    image = array_to_image(array_784)\n",
    "    pred = model.predict(array_784.reshape(1, -1))\n",
    "    print(f\"Predicted Label: {pred[0]}\")\n",
    "    return image, pred[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e977448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500, Loss: 0.6065\n",
      "Epoch 200/500, Loss: 0.4855\n",
      "Epoch 300/500, Loss: 0.4359\n",
      "Epoch 400/500, Loss: 0.4072\n",
      "Epoch 500/500, Loss: 0.3880\n",
      "\n",
      "Evaluation Metrics (on Validation Set):\n",
      "Accuracy:  0.8974\n",
      "Precision: 0.8963\n",
      "Recall:    0.8949\n",
      "F1 Score:  0.8956\n",
      "\n",
      "Sample Test Predictions: [2 0 9 9 3 7 0 3 0 3]\n",
      "\n",
      "Predictions saved to mnist_predictions.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.01176471, 0.54509804, 0.99215686, 0.81176471, 0.09411765,\n",
       "         0.50196078, 0.52156863, 0.51764706, 0.51764706, 0.20392157,\n",
       "         0.01568627, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.06666667,\n",
       "         0.53333333, 0.98823529, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.99215686, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.54901961, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01568627, 0.21176471, 0.86666667,\n",
       "         0.98823529, 0.98823529, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.99215686, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.75294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.01176471, 0.49411765, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.98823529, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.80784314, 0.80392157, 0.81568627, 0.98823529, 0.98823529,\n",
       "         0.75294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.38823529, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.92156863, 0.59215686, 0.28235294, 0.28235294,\n",
       "         0.01568627, 0.        , 0.09803922, 0.98823529, 0.98823529,\n",
       "         0.75294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.51764706, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.67058824, 0.16862745, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.23137255, 0.98823529, 0.98823529,\n",
       "         0.75294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.51764706, 0.98823529, 0.98823529, 0.45098039,\n",
       "         0.05490196, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.03921569, 0.90980392, 0.98823529, 0.98823529,\n",
       "         0.36862745, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.0745098 , 0.41176471, 0.31764706, 0.04705882,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.45882353, 0.98823529, 0.98823529, 0.82352941,\n",
       "         0.03921569, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.72156863, 0.98823529, 0.98823529, 0.37254902,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.67843137, 0.99215686, 0.98823529, 0.98823529, 0.64313725,\n",
       "         0.36078431, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.03921569, 0.43529412, 0.70196078, 0.99215686,\n",
       "         0.99215686, 1.        , 0.99215686, 0.99215686, 0.99215686,\n",
       "         0.99215686, 0.49803922, 0.01176471, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.06666667,\n",
       "         0.43529412, 0.89019608, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.99215686, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.98823529, 0.64705882, 0.35294118, 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.15686275, 0.86666667,\n",
       "         0.98823529, 0.98823529, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.99215686, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.98823529, 0.98823529, 0.84705882, 0.61568627,\n",
       "         0.02745098, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.15686275, 0.86666667, 0.98823529,\n",
       "         0.98823529, 0.98823529, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.89411765, 0.75294118, 0.39607843, 0.8       ,\n",
       "         0.8       , 0.85490196, 0.98823529, 0.91764706, 0.8       ,\n",
       "         0.03529412, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.14901961, 0.87058824, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.98823529, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.76078431, 0.1372549 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.08235294, 0.28235294, 0.17647059, 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.51764706, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.98823529, 0.98823529, 0.98823529, 0.5254902 ,\n",
       "         0.01176471, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.51764706, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.98823529, 0.87843137, 0.47843137, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.51764706, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.98823529, 0.87843137, 0.18039216, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.51764706, 0.98823529, 0.98823529, 0.98823529,\n",
       "         0.88627451, 0.17647059, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2745098 , 0.56078431, 0.98823529, 0.35686275,\n",
       "         0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]),\n",
       " np.int64(2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"Data/train.csv\")\n",
    "test = pd.read_csv(\"Data/test.csv\")\n",
    "\n",
    "# Train data has labels\n",
    "X = train.drop(columns=['label']).values / 255.0\n",
    "y = train['label'].values\n",
    "\n",
    "# Split training data (use part as validation set)\n",
    "split_ratio = 0.8\n",
    "split_idx = int(split_ratio * len(X))\n",
    "\n",
    "X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "y_train, y_val = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# Test data (no labels)\n",
    "X_test = test.values / 255.0\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegressionScratch(lr=0.1, epochs=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "acc = accuracy_score(y_val, y_val_pred)\n",
    "prec = precision_score(y_val, y_val_pred, num_classes)\n",
    "rec = recall_score(y_val, y_val_pred, num_classes)\n",
    "f1 = f1_score(y_val, y_val_pred, num_classes)\n",
    "\n",
    "print(\"\\nEvaluation Metrics (on Validation Set):\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "# Predict labels for test.csv (no ground truth)\n",
    "test_predictions = model.predict(X_test)\n",
    "print(\"\\nSample Test Predictions:\", test_predictions[:10])\n",
    "\n",
    "# Optional: Save results\n",
    "submission = pd.DataFrame({'ImageId': np.arange(1, len(test_predictions) + 1),\n",
    "                           'Label': test_predictions})\n",
    "submission.to_csv(\"mnist_predictions.csv\", index=False)\n",
    "print(\"\\nPredictions saved to mnist_predictions.csv\")\n",
    "\n",
    "# Test on one random image from validation set\n",
    "sample = X_val[3]\n",
    "predict_and_show(sample, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
