{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b0b429a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150, 6)\n",
      "\n",
      "Dataset head:\n",
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n",
      "\n",
      "Class distribution:\n",
      "Species\n",
      "Iris-setosa        50\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class mapping: {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n",
      "Features shape: (150, 5)\n",
      "Target shape: (150,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Data/iris.csv')\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nDataset head:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check the target distribution\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df.iloc[:, -1].value_counts())\n",
    "\n",
    "# Prepare features and target\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Convert target to numerical labels\n",
    "unique_classes = np.unique(y)\n",
    "class_to_num = {cls: i for i, cls in enumerate(unique_classes)}\n",
    "num_to_class = {i: cls for i, cls in enumerate(unique_classes)}\n",
    "y_num = np.array([class_to_num[cls] for cls in y])\n",
    "\n",
    "print(f\"\\nClass mapping: {class_to_num}\")\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y_num.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "215c7e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 80:10:10 split...\n",
      "Creating 70:15:15 split...\n",
      "\n",
      "80:10:10 split - Train: 120, Val: 15, Test: 15\n",
      "70:15:15 split - Train: 105, Val: 21, Test: 24\n"
     ]
    }
   ],
   "source": [
    "def stratified_split(X, y, train_size, val_size, test_size, random_state=42):\n",
    "    \"\"\"Stratified split maintaining class proportions\"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Get indices for each class\n",
    "    class_indices = {}\n",
    "    for cls in np.unique(y):\n",
    "        class_indices[cls] = np.where(y == cls)[0]\n",
    "    \n",
    "    train_indices, val_indices, test_indices = [], [], []\n",
    "    \n",
    "    for cls, indices in class_indices.items():\n",
    "        np.random.shuffle(indices)\n",
    "        n_samples = len(indices)\n",
    "        \n",
    "        n_train = int(n_samples * train_size)\n",
    "        n_val = int(n_samples * val_size)\n",
    "        \n",
    "        train_indices.extend(indices[:n_train])\n",
    "        val_indices.extend(indices[n_train:n_train+n_val])\n",
    "        test_indices.extend(indices[n_train+n_val:])\n",
    "    \n",
    "    # Shuffle final indices\n",
    "    np.random.shuffle(train_indices)\n",
    "    np.random.shuffle(val_indices)\n",
    "    np.random.shuffle(test_indices)\n",
    "    \n",
    "    return (X[train_indices], X[val_indices], X[test_indices], \n",
    "            y[train_indices], y[val_indices], y[test_indices])\n",
    "\n",
    "# Create splits for both proportions\n",
    "print(\"Creating 80:10:10 split...\")\n",
    "X_train_80, X_val_80, X_test_80, y_train_80, y_val_80, y_test_80 = stratified_split(\n",
    "    X, y_num, 0.8, 0.1, 0.1)\n",
    "\n",
    "print(\"Creating 70:15:15 split...\")\n",
    "X_train_70, X_val_70, X_test_70, y_train_70, y_val_70, y_test_70 = stratified_split(\n",
    "    X, y_num, 0.7, 0.15, 0.15)\n",
    "\n",
    "print(f\"\\n80:10:10 split - Train: {len(X_train_80)}, Val: {len(X_val_80)}, Test: {len(X_test_80)}\")\n",
    "print(f\"70:15:15 split - Train: {len(X_train_70)}, Val: {len(X_val_70)}, Test: {len(X_test_70)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99285dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Add bias term to X\n",
    "        X_with_bias = np.column_stack([np.ones(X.shape[0]), X])\n",
    "        \n",
    "        # Compute weights using normal equation: (X^T X)^-1 X^T y\n",
    "        self.weights = np.linalg.pinv(X_with_bias.T @ X_with_bias) @ X_with_bias.T @ y\n",
    "        self.bias = self.weights[0]\n",
    "        self.weights = self.weights[1:]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return X @ self.weights + self.bias\n",
    "\n",
    "class LinearClassifier:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.classes = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            # Create binary target (1 for current class, 0 for others)\n",
    "            y_binary = (y == cls).astype(int)\n",
    "            \n",
    "            # Train linear regression for this class\n",
    "            model = LinearRegression()\n",
    "            model.fit(X, y_binary)\n",
    "            self.models[cls] = model\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Get predictions from all models\n",
    "        predictions = {}\n",
    "        for cls, model in self.models.items():\n",
    "            predictions[cls] = model.predict(X)\n",
    "        \n",
    "        # Choose class with highest prediction for each sample\n",
    "        pred_array = np.array([predictions[cls] for cls in self.classes]).T\n",
    "        return self.classes[np.argmax(pred_array, axis=1)]\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        predictions = {}\n",
    "        for cls, model in self.models.items():\n",
    "            predictions[cls] = model.predict(X)\n",
    "        \n",
    "        return np.array([predictions[cls] for cls in self.classes]).T\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def classification_report(y_true, y_pred, classes):\n",
    "    report = {}\n",
    "    for cls in classes:\n",
    "        tp = np.sum((y_true == cls) & (y_pred == cls))\n",
    "        fp = np.sum((y_true != cls) & (y_pred == cls))\n",
    "        fn = np.sum((y_true == cls) & (y_pred != cls))\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        report[cls] = {'precision': precision, 'recall': recall, 'f1': f1}\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d96c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_oversampling(X, y):\n",
    "    \"\"\"Simple random oversampling to balance classes\"\"\"\n",
    "    class_counts = Counter(y)\n",
    "    max_count = max(class_counts.values())\n",
    "    \n",
    "    X_resampled = []\n",
    "    y_resampled = []\n",
    "    \n",
    "    for cls in np.unique(y):\n",
    "        cls_indices = np.where(y == cls)[0]\n",
    "        cls_X = X[cls_indices]\n",
    "        cls_y = y[cls_indices]\n",
    "        \n",
    "        # Randomly sample with replacement to reach max_count\n",
    "        n_to_sample = max_count\n",
    "        sampled_indices = np.random.choice(len(cls_X), size=n_to_sample, replace=True)\n",
    "        \n",
    "        X_resampled.append(cls_X[sampled_indices])\n",
    "        y_resampled.append(cls_y[sampled_indices])\n",
    "    \n",
    "    return np.vstack(X_resampled), np.hstack(y_resampled)\n",
    "\n",
    "def evaluate_model(X_train, y_train, X_val, y_val, X_test, y_test, model_name):\n",
    "    \"\"\"Train and evaluate a linear classifier\"\"\"\n",
    "    # Train model\n",
    "    clf = LinearClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    train_pred = clf.predict(X_train)\n",
    "    val_pred = clf.predict(X_val)\n",
    "    test_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Accuracies\n",
    "    train_acc = accuracy_score(y_train, train_pred)\n",
    "    val_acc = accuracy_score(y_val, val_pred)\n",
    "    test_acc = accuracy_score(y_test, test_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Val Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # Detailed classification report for test set\n",
    "    report = classification_report(y_test, test_pred, np.unique(y_test))\n",
    "    print(\"\\nTest Set Classification Report:\")\n",
    "    for cls, metrics in report.items():\n",
    "        cls_name = num_to_class[cls]\n",
    "        print(f\"Class {cls_name}: Precision={metrics['precision']:.4f}, \"\n",
    "              f\"Recall={metrics['recall']:.4f}, F1={metrics['f1']:.4f}\")\n",
    "    \n",
    "    return {'train_acc': train_acc, 'val_acc': val_acc, 'test_acc': test_acc, 'report': report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3822e534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "BASELINE MODELS (NO OVERSAMPLING)\n",
      "==================================================\n",
      "\n",
      "80:10:10 Baseline Results:\n",
      "Train Accuracy: 0.8750\n",
      "Val Accuracy: 1.0000\n",
      "Test Accuracy: 0.8667\n",
      "\n",
      "Test Set Classification Report:\n",
      "Class Iris-setosa: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
      "Class Iris-versicolor: Precision=0.7143, Recall=1.0000, F1=0.8333\n",
      "Class Iris-virginica: Precision=1.0000, Recall=0.6000, F1=0.7500\n",
      "\n",
      "70:15:15 Baseline Results:\n",
      "Train Accuracy: 0.8952\n",
      "Val Accuracy: 0.8095\n",
      "Test Accuracy: 0.9167\n",
      "\n",
      "Test Set Classification Report:\n",
      "Class Iris-setosa: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
      "Class Iris-versicolor: Precision=0.8000, Recall=1.0000, F1=0.8889\n",
      "Class Iris-virginica: Precision=1.0000, Recall=0.7500, F1=0.8571\n",
      "\n",
      "==================================================\n",
      "RANDOM OVERSAMPLING\n",
      "==================================================\n",
      "\n",
      "Original 80:10:10 train class distribution: Counter({np.int64(0): 40, np.int64(2): 40, np.int64(1): 40})\n",
      "After oversampling: Counter({np.int64(0): 40, np.int64(1): 40, np.int64(2): 40})\n",
      "\n",
      "80:10:10 Random Oversampled Results:\n",
      "Train Accuracy: 0.8833\n",
      "Val Accuracy: 1.0000\n",
      "Test Accuracy: 0.8667\n",
      "\n",
      "Test Set Classification Report:\n",
      "Class Iris-setosa: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
      "Class Iris-versicolor: Precision=0.7143, Recall=1.0000, F1=0.8333\n",
      "Class Iris-virginica: Precision=1.0000, Recall=0.6000, F1=0.7500\n",
      "\n",
      "Original 70:15:15 train class distribution: Counter({np.int64(1): 35, np.int64(0): 35, np.int64(2): 35})\n",
      "After oversampling: Counter({np.int64(0): 35, np.int64(1): 35, np.int64(2): 35})\n",
      "\n",
      "70:15:15 Random Oversampled Results:\n",
      "Train Accuracy: 0.9143\n",
      "Val Accuracy: 0.8095\n",
      "Test Accuracy: 0.9167\n",
      "\n",
      "Test Set Classification Report:\n",
      "Class Iris-setosa: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
      "Class Iris-versicolor: Precision=0.8000, Recall=1.0000, F1=0.8889\n",
      "Class Iris-virginica: Precision=1.0000, Recall=0.7500, F1=0.8571\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "# Baseline models (no oversampling)\n",
    "print(\"=\"*50)\n",
    "print(\"BASELINE MODELS (NO OVERSAMPLING)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "results['80-10-10_baseline'] = evaluate_model(\n",
    "    X_train_80, y_train_80, X_val_80, y_val_80, X_test_80, y_test_80, \n",
    "    \"80:10:10 Baseline\"\n",
    ")\n",
    "\n",
    "results['70-15-15_baseline'] = evaluate_model(\n",
    "    X_train_70, y_train_70, X_val_70, y_val_70, X_test_70, y_test_70, \n",
    "    \"70:15:15 Baseline\"\n",
    ")\n",
    "\n",
    "# Random Oversampling\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RANDOM OVERSAMPLING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Random oversampling for 80:10:10 split\n",
    "print(f\"\\nOriginal 80:10:10 train class distribution: {Counter(y_train_80)}\")\n",
    "X_train_80_over, y_train_80_over = random_oversampling(X_train_80, y_train_80)\n",
    "print(f\"After oversampling: {Counter(y_train_80_over)}\")\n",
    "\n",
    "results['80-10-10_oversampled'] = evaluate_model(\n",
    "    X_train_80_over, y_train_80_over, X_val_80, y_val_80, X_test_80, y_test_80,\n",
    "    \"80:10:10 Random Oversampled\"\n",
    ")\n",
    "\n",
    "# Random oversampling for 70:15:15 split\n",
    "print(f\"\\nOriginal 70:15:15 train class distribution: {Counter(y_train_70)}\")\n",
    "X_train_70_over, y_train_70_over = random_oversampling(X_train_70, y_train_70)\n",
    "print(f\"After oversampling: {Counter(y_train_70_over)}\")\n",
    "\n",
    "results['70-15-15_oversampled'] = evaluate_model(\n",
    "    X_train_70_over, y_train_70_over, X_val_70, y_val_70, X_test_70, y_test_70,\n",
    "    \"70:15:15 Random Oversampled\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f689fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\"Calculate euclidean distance between two points\"\"\"\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "def find_k_nearest_neighbors(X, point_idx, k=2):\n",
    "    \"\"\"Find k nearest neighbors for a given point\"\"\"\n",
    "    point = X[point_idx]\n",
    "    distances = []\n",
    "    \n",
    "    for i, other_point in enumerate(X):\n",
    "        if i != point_idx:\n",
    "            dist = euclidean_distance(point, other_point)\n",
    "            distances.append((dist, i))\n",
    "    \n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    return [idx for _, idx in distances[:k]]\n",
    "\n",
    "def smote_random_pair(X, y, k=2):\n",
    "    \"\"\"SMOTE with random 2 samples from minority class\"\"\"\n",
    "    class_counts = Counter(y)\n",
    "    max_count = max(class_counts.values())\n",
    "    \n",
    "    X_synthetic = []\n",
    "    y_synthetic = []\n",
    "    \n",
    "    for cls in np.unique(y):\n",
    "        cls_indices = np.where(y == cls)[0]\n",
    "        cls_X = X[cls_indices]\n",
    "        current_count = len(cls_X)\n",
    "        \n",
    "        X_synthetic.append(cls_X)\n",
    "        y_synthetic.append(np.full(current_count, cls))\n",
    "        \n",
    "        if current_count < max_count:\n",
    "            n_synthetic = max_count - current_count\n",
    "            \n",
    "            for _ in range(n_synthetic):\n",
    "                # Randomly select 2 samples from minority class\n",
    "                if len(cls_X) >= 2:\n",
    "                    idx1, idx2 = np.random.choice(len(cls_X), size=2, replace=False)\n",
    "                    x1, x2 = cls_X[idx1], cls_X[idx2]\n",
    "                else:\n",
    "                    # If only one sample, duplicate it\n",
    "                    x1 = x2 = cls_X[0]\n",
    "                \n",
    "                # Generate synthetic sample\n",
    "                alpha = np.random.random()\n",
    "                synthetic_sample = x1 + alpha * (x2 - x1)\n",
    "                \n",
    "                X_synthetic.append([synthetic_sample])\n",
    "                y_synthetic.append([cls])\n",
    "    \n",
    "    return np.vstack(X_synthetic), np.hstack(y_synthetic)\n",
    "\n",
    "def smote_nearest_neighbors(X, y, k=1):\n",
    "    \"\"\"SMOTE with nearest neighbor approach\"\"\"\n",
    "    class_counts = Counter(y)\n",
    "    max_count = max(class_counts.values())\n",
    "    \n",
    "    X_synthetic = []\n",
    "    y_synthetic = []\n",
    "    \n",
    "    for cls in np.unique(y):\n",
    "        cls_indices = np.where(y == cls)[0]\n",
    "        cls_X = X[cls_indices]\n",
    "        current_count = len(cls_X)\n",
    "        \n",
    "        X_synthetic.append(cls_X)\n",
    "        y_synthetic.append(np.full(current_count, cls))\n",
    "        \n",
    "        if current_count < max_count:\n",
    "            n_synthetic = max_count - current_count\n",
    "            \n",
    "            for _ in range(n_synthetic):\n",
    "                # Randomly select one sample from minority class\n",
    "                random_idx = np.random.randint(0, len(cls_X))\n",
    "                selected_sample = cls_X[random_idx]\n",
    "                \n",
    "                # Find its nearest neighbor\n",
    "                if len(cls_X) > 1:\n",
    "                    neighbors = find_k_nearest_neighbors(cls_X, random_idx, k=1)\n",
    "                    neighbor_sample = cls_X[neighbors[0]]\n",
    "                else:\n",
    "                    neighbor_sample = selected_sample\n",
    "                \n",
    "                # Generate synthetic sample\n",
    "                alpha = np.random.random()\n",
    "                synthetic_sample = selected_sample + alpha * (neighbor_sample - selected_sample)\n",
    "                \n",
    "                X_synthetic.append([synthetic_sample])\n",
    "                y_synthetic.append([cls])\n",
    "    \n",
    "    return np.vstack(X_synthetic), np.hstack(y_synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33e97eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "SMOTE WITH RANDOM PAIRS\n",
      "==================================================\n",
      "\n",
      "80:10:10 SMOTE random pairs - Final distribution: Counter({np.int64(0): 40, np.int64(1): 40, np.int64(2): 40})\n",
      "\n",
      "80:10:10 SMOTE Random Pairs Results:\n",
      "Train Accuracy: 0.8750\n",
      "Val Accuracy: 1.0000\n",
      "Test Accuracy: 0.8667\n",
      "\n",
      "Test Set Classification Report:\n",
      "Class Iris-setosa: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
      "Class Iris-versicolor: Precision=0.7143, Recall=1.0000, F1=0.8333\n",
      "Class Iris-virginica: Precision=1.0000, Recall=0.6000, F1=0.7500\n",
      "\n",
      "70:15:15 SMOTE random pairs - Final distribution: Counter({np.int64(0): 35, np.int64(1): 35, np.int64(2): 35})\n",
      "\n",
      "70:15:15 SMOTE Random Pairs Results:\n",
      "Train Accuracy: 0.8952\n",
      "Val Accuracy: 0.8095\n",
      "Test Accuracy: 0.9167\n",
      "\n",
      "Test Set Classification Report:\n",
      "Class Iris-setosa: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
      "Class Iris-versicolor: Precision=0.8000, Recall=1.0000, F1=0.8889\n",
      "Class Iris-virginica: Precision=1.0000, Recall=0.7500, F1=0.8571\n",
      "\n",
      "==================================================\n",
      "SMOTE WITH NEAREST NEIGHBORS\n",
      "==================================================\n",
      "\n",
      "80:10:10 SMOTE nearest neighbors - Final distribution: Counter({np.int64(0): 40, np.int64(1): 40, np.int64(2): 40})\n",
      "\n",
      "80:10:10 SMOTE Nearest Neighbors Results:\n",
      "Train Accuracy: 0.8750\n",
      "Val Accuracy: 1.0000\n",
      "Test Accuracy: 0.8667\n",
      "\n",
      "Test Set Classification Report:\n",
      "Class Iris-setosa: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
      "Class Iris-versicolor: Precision=0.7143, Recall=1.0000, F1=0.8333\n",
      "Class Iris-virginica: Precision=1.0000, Recall=0.6000, F1=0.7500\n",
      "\n",
      "70:15:15 SMOTE nearest neighbors - Final distribution: Counter({np.int64(0): 35, np.int64(1): 35, np.int64(2): 35})\n",
      "\n",
      "70:15:15 SMOTE Nearest Neighbors Results:\n",
      "Train Accuracy: 0.8952\n",
      "Val Accuracy: 0.8095\n",
      "Test Accuracy: 0.9167\n",
      "\n",
      "Test Set Classification Report:\n",
      "Class Iris-setosa: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
      "Class Iris-versicolor: Precision=0.8000, Recall=1.0000, F1=0.8889\n",
      "Class Iris-virginica: Precision=1.0000, Recall=0.7500, F1=0.8571\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SMOTE WITH RANDOM PAIRS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# SMOTE with random pairs for 80:10:10 split\n",
    "X_train_80_smote1, y_train_80_smote1 = smote_random_pair(X_train_80, y_train_80)\n",
    "print(f\"\\n80:10:10 SMOTE random pairs - Final distribution: {Counter(y_train_80_smote1)}\")\n",
    "\n",
    "results['80-10-10_smote_random'] = evaluate_model(\n",
    "    X_train_80_smote1, y_train_80_smote1, X_val_80, y_val_80, X_test_80, y_test_80,\n",
    "    \"80:10:10 SMOTE Random Pairs\"\n",
    ")\n",
    "\n",
    "# SMOTE with random pairs for 70:15:15 split\n",
    "X_train_70_smote1, y_train_70_smote1 = smote_random_pair(X_train_70, y_train_70)\n",
    "print(f\"\\n70:15:15 SMOTE random pairs - Final distribution: {Counter(y_train_70_smote1)}\")\n",
    "\n",
    "results['70-15-15_smote_random'] = evaluate_model(\n",
    "    X_train_70_smote1, y_train_70_smote1, X_val_70, y_val_70, X_test_70, y_test_70,\n",
    "    \"70:15:15 SMOTE Random Pairs\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SMOTE WITH NEAREST NEIGHBORS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# SMOTE with nearest neighbors for 80:10:10 split\n",
    "X_train_80_smote2, y_train_80_smote2 = smote_nearest_neighbors(X_train_80, y_train_80)\n",
    "print(f\"\\n80:10:10 SMOTE nearest neighbors - Final distribution: {Counter(y_train_80_smote2)}\")\n",
    "\n",
    "results['80-10-10_smote_nn'] = evaluate_model(\n",
    "    X_train_80_smote2, y_train_80_smote2, X_val_80, y_val_80, X_test_80, y_test_80,\n",
    "    \"80:10:10 SMOTE Nearest Neighbors\"\n",
    ")\n",
    "\n",
    "# SMOTE with nearest neighbors for 70:15:15 split\n",
    "X_train_70_smote2, y_train_70_smote2 = smote_nearest_neighbors(X_train_70, y_train_70)\n",
    "print(f\"\\n70:15:15 SMOTE nearest neighbors - Final distribution: {Counter(y_train_70_smote2)}\")\n",
    "\n",
    "results['70-15-15_smote_nn'] = evaluate_model(\n",
    "    X_train_70_smote2, y_train_70_smote2, X_val_70, y_val_70, X_test_70, y_test_70,\n",
    "    \"70:15:15 SMOTE Nearest Neighbors\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d78c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE PERFORMANCE COMPARISON\n",
      "======================================================================\n",
      "Method                         Split      Train Acc    Val Acc    Test Acc  \n",
      "----------------------------------------------------------------------\n",
      "Baseline                       80-10-10   0.8750       1.0000     0.8667    \n",
      "Baseline                       70-15-15   0.8952       0.8095     0.9167    \n",
      "Random Oversampling            80-10-10   0.8833       1.0000     0.8667    \n",
      "Random Oversampling            70-15-15   0.9143       0.8095     0.9167    \n",
      "SMOTE Random Pairs             80-10-10   0.8750       1.0000     0.8667    \n",
      "SMOTE Random Pairs             70-15-15   0.8952       0.8095     0.9167    \n",
      "SMOTE Nearest Neighbors        80-10-10   0.8750       1.0000     0.8667    \n",
      "SMOTE Nearest Neighbors        70-15-15   0.8952       0.8095     0.9167    \n",
      "\n",
      "======================================================================\n",
      "BEST PERFORMING METHODS BY TEST ACCURACY\n",
      "======================================================================\n",
      "1. Baseline (70-15-15): Test Accuracy = 0.9167\n",
      "2. Oversampled (70-15-15): Test Accuracy = 0.9167\n",
      "3. Smote Random (70-15-15): Test Accuracy = 0.9167\n",
      "\n",
      "======================================================================\n",
      "SUMMARY INSIGHTS\n",
      "======================================================================\n",
      "Average Test Accuracy - 80:10:10 split: 0.8667\n",
      "Average Test Accuracy - 70:15:15 split: 0.9167\n",
      "\n",
      "Average Test Accuracy by Method:\n",
      "Baseline: 0.8917\n",
      "Random Oversampling: 0.8917\n",
      "SMOTE Random Pairs: 0.8917\n",
      "SMOTE Nearest Neighbors: 0.8917\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPREHENSIVE PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create comparison table\n",
    "print(f\"{'Method':<30} {'Split':<10} {'Train Acc':<12} {'Val Acc':<10} {'Test Acc':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "methods = [\n",
    "    ('Baseline', 'baseline'),\n",
    "    ('Random Oversampling', 'oversampled'),\n",
    "    ('SMOTE Random Pairs', 'smote_random'),\n",
    "    ('SMOTE Nearest Neighbors', 'smote_nn')\n",
    "]\n",
    "\n",
    "splits = [('80-10-10', '80-10-10'), ('70-15-15', '70-15-15')]\n",
    "\n",
    "for method_name, method_key in methods:\n",
    "    for split_name, split_key in splits:\n",
    "        key = f\"{split_key}_{method_key}\"\n",
    "        if key in results:\n",
    "            result = results[key]\n",
    "            print(f\"{method_name:<30} {split_name:<10} {result['train_acc']:<12.4f} \"\n",
    "                  f\"{result['val_acc']:<10.4f} {result['test_acc']:<10.4f}\")\n",
    "\n",
    "# Find best performing methods\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"BEST PERFORMING METHODS BY TEST ACCURACY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1]['test_acc'], reverse=True)\n",
    "\n",
    "for i, (method, result) in enumerate(sorted_results[:3], 1):\n",
    "    method_parts = method.split('_')\n",
    "    split_info = method_parts[0]\n",
    "    method_type = '_'.join(method_parts[1:])\n",
    "    \n",
    "    print(f\"{i}. {method_type.replace('_', ' ').title()} ({split_info}): \"\n",
    "          f\"Test Accuracy = {result['test_acc']:.4f}\")\n",
    "\n",
    "# Summary insights\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SUMMARY INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Compare splits\n",
    "split_80_methods = [k for k in results.keys() if k.startswith('80-10-10')]\n",
    "split_70_methods = [k for k in results.keys() if k.startswith('70-15-15')]\n",
    "\n",
    "avg_80 = np.mean([results[k]['test_acc'] for k in split_80_methods])\n",
    "avg_70 = np.mean([results[k]['test_acc'] for k in split_70_methods])\n",
    "\n",
    "print(f\"Average Test Accuracy - 80:10:10 split: {avg_80:.4f}\")\n",
    "print(f\"Average Test Accuracy - 70:15:15 split: {avg_70:.4f}\")\n",
    "\n",
    "# Compare methods across splits\n",
    "method_performance = {}\n",
    "for method_name, method_key in methods:\n",
    "    accuracies = []\n",
    "    for split_name, split_key in splits:\n",
    "        key = f\"{split_key}_{method_key}\"\n",
    "        if key in results:\n",
    "            accuracies.append(results[key]['test_acc'])\n",
    "    if accuracies:\n",
    "        method_performance[method_name] = np.mean(accuracies)\n",
    "\n",
    "print(f\"\\nAverage Test Accuracy by Method:\")\n",
    "for method, avg_acc in sorted(method_performance.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{method}: {avg_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
