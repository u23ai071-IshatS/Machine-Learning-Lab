{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aace276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb026dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "   age           job  marital  education default  balance housing loan  \\\n",
      "0   58    management  married   tertiary      no     2143     yes   no   \n",
      "1   44    technician   single  secondary      no       29     yes   no   \n",
      "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
      "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
      "4   33       unknown   single    unknown      no        1      no   no   \n",
      "\n",
      "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
      "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
      "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
      "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
      "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
      "4  unknown    5   may       198         1     -1         0  unknown  no   \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  y          45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n",
      "None \n",
      "\n",
      "Missing values per column:\n",
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "default      0\n",
      "balance      0\n",
      "housing      0\n",
      "loan         0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64 \n",
      "\n",
      "Target distribution (y):\n",
      "y\n",
      "no     39922\n",
      "yes     5289\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Numeric column summary:\n",
      "                age        balance           day      duration      campaign  \\\n",
      "count  45211.000000   45211.000000  45211.000000  45211.000000  45211.000000   \n",
      "mean      40.936210    1362.272058     15.806419    258.163080      2.763841   \n",
      "std       10.618762    3044.765829      8.322476    257.527812      3.098021   \n",
      "min       18.000000   -8019.000000      1.000000      0.000000      1.000000   \n",
      "25%       33.000000      72.000000      8.000000    103.000000      1.000000   \n",
      "50%       39.000000     448.000000     16.000000    180.000000      2.000000   \n",
      "75%       48.000000    1428.000000     21.000000    319.000000      3.000000   \n",
      "max       95.000000  102127.000000     31.000000   4918.000000     63.000000   \n",
      "\n",
      "              pdays      previous  \n",
      "count  45211.000000  45211.000000  \n",
      "mean      40.197828      0.580323  \n",
      "std      100.128746      2.303441  \n",
      "min       -1.000000      0.000000  \n",
      "25%       -1.000000      0.000000  \n",
      "50%       -1.000000      0.000000  \n",
      "75%       -1.000000      0.000000  \n",
      "max      871.000000    275.000000   \n",
      "\n",
      "Unique values per categorical column:\n",
      "job: ['management' 'technician' 'entrepreneur' 'blue-collar' 'unknown'\n",
      " 'retired' 'admin.' 'services' 'self-employed' 'unemployed' 'housemaid'\n",
      " 'student']\n",
      "marital: ['married' 'single' 'divorced']\n",
      "education: ['tertiary' 'secondary' 'unknown' 'primary']\n",
      "default: ['no' 'yes']\n",
      "housing: ['yes' 'no']\n",
      "loan: ['no' 'yes']\n",
      "contact: ['unknown' 'cellular' 'telephone']\n",
      "month: ['may' 'jun' 'jul' 'aug' 'oct' 'nov' 'dec' 'jan' 'feb' 'mar' 'apr' 'sep']\n",
      "poutcome: ['unknown' 'failure' 'other' 'success']\n",
      "y: ['no' 'yes']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"bank-full.csv\", sep=';')   # original file uses semicolon separator\n",
    "\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head(), \"\\n\")\n",
    "\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info(), \"\\n\")\n",
    "\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum(), \"\\n\")\n",
    "\n",
    "print(\"Target distribution (y):\")\n",
    "print(df['y'].value_counts(), \"\\n\")\n",
    "\n",
    "# Numerical summary\n",
    "print(\"Numeric column summary:\")\n",
    "print(df.describe(), \"\\n\")\n",
    "\n",
    "# Categorical summary (unique values)\n",
    "print(\"Unique values per categorical column:\")\n",
    "for col in df.select_dtypes('object').columns:\n",
    "    print(f\"{col}: {df[col].unique()}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d91fa2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 36168, Test samples: 9043\n",
      "Number of features: 42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encode binary yes/no columns\n",
    "binary_cols = ['default', 'housing', 'loan', 'y']\n",
    "for col in binary_cols:\n",
    "    df[col] = df[col].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y'].values\n",
    "\n",
    "# One-hot encode categorical columns (non-binary)\n",
    "cat_cols = ['job', 'marital', 'education', 'contact', 'month', 'poutcome']\n",
    "X_encoded = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "num_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "X_encoded[num_cols] = scaler.fit_transform(X_encoded[num_cols])\n",
    "\n",
    "# Ensure all features are numeric\n",
    "X_encoded = X_encoded.astype(float)\n",
    "\n",
    "# Convert to NumPy array explicitly as float\n",
    "X = np.asarray(X_encoded.values, dtype=float)\n",
    "\n",
    "# Shuffle data\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "\n",
    "# Train-test split (80:20)\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e5a1d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model...\n",
      "\n",
      "Epoch    0  Loss: 0.667529\n",
      "Epoch  500  Loss: 0.265251\n",
      "Epoch 1000  Loss: 0.258293\n",
      "Epoch 1500  Loss: 0.254255\n",
      "Epoch 2000  Loss: 0.251468\n",
      "Epoch 2500  Loss: 0.249413\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def compute_cost(X, y, weights):\n",
    "    n = len(y)\n",
    "    h = sigmoid(X.dot(weights))\n",
    "    epsilon = 1e-8\n",
    "    cost = -(1/n) * np.sum(y*np.log(h+epsilon) + (1-y)*np.log(1-h+epsilon))\n",
    "    return cost\n",
    "\n",
    "def gradient_descent(X, y, lr=0.01, epochs=2000):\n",
    "    n, m = X.shape\n",
    "    weights = np.zeros(m)\n",
    "    for i in range(epochs):\n",
    "        h = sigmoid(X.dot(weights))\n",
    "        gradient = (1/n) * X.T.dot(h - y)\n",
    "        weights -= lr * gradient\n",
    "        if i % 500 == 0:\n",
    "            loss = compute_cost(X, y, weights)\n",
    "            print(f\"Epoch {i:4d}  Loss: {loss:.6f}\")\n",
    "    return weights\n",
    "\n",
    "def predict(X, weights, threshold=0.5):\n",
    "    return (sigmoid(X.dot(weights)) >= threshold).astype(int)\n",
    "\n",
    "# Add intercept term\n",
    "X_train_bias = np.hstack([np.ones((X_train.shape[0], 1)), X_train])\n",
    "X_test_bias = np.hstack([np.ones((X_test.shape[0], 1)), X_test])\n",
    "\n",
    "# Train model\n",
    "print(\"Training Logistic Regression model...\\n\")\n",
    "weights = gradient_descent(X_train_bias, y_train, lr=0.05, epochs=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e3a6512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Evaluation Metrics (on Test Set):\n",
      "\n",
      "Accuracy  : 0.9018\n",
      "Precision : 0.6827\n",
      "Recall    : 0.3076\n",
      "F1-score  : 0.4241\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7828  152]\n",
      " [ 736  327]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.91      0.98      0.95      7980\n",
      "         Yes       0.68      0.31      0.42      1063\n",
      "\n",
      "    accuracy                           0.90      9043\n",
      "   macro avg       0.80      0.64      0.69      9043\n",
      "weighted avg       0.89      0.90      0.88      9043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test_bias, weights)\n",
    "\n",
    "print(\"\\nðŸ”¹ Evaluation Metrics (on Test Set):\\n\")\n",
    "print(f\"Accuracy  : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision : {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall    : {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1-score  : {f1_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No', 'Yes']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
