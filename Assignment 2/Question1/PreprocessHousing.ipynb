{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "46765fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
      "0  13300000  7420         4          2        3      yes        no       no   \n",
      "1  12250000  8960         4          4        4      yes        no       no   \n",
      "2  12250000  9960         3          2        2      yes        no      yes   \n",
      "3  12215000  7500         4          2        2      yes        no      yes   \n",
      "4  11410000  7420         4          1        2      yes       yes      yes   \n",
      "\n",
      "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
      "0              no             yes        2      yes        furnished  \n",
      "1              no             yes        3       no        furnished  \n",
      "2              no              no        2      yes   semi-furnished  \n",
      "3              no             yes        3      yes        furnished  \n",
      "4              no             yes        2       no        furnished  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../Data/Housing.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37273e62",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "First, we need to convert categorical variables into numerical format:\n",
    "- Binary variables (yes/no) will be converted to 1/0\n",
    "- Furnishing status will be encoded using one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "642834b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert binary variables to 0/1\n",
    "binary_columns = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
    "for col in binary_columns:\n",
    "    df[col] = (df[col] == 'yes').astype(int)\n",
    "\n",
    "# One-hot encode furnishing status\n",
    "df = pd.get_dummies(df, columns=['furnishingstatus'], prefix='furnishing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958c69df",
   "metadata": {},
   "source": [
    "# Feature Selection and Target Variable\n",
    "We'll separate our features and target variable:\n",
    "- Target: price\n",
    "- Features: all other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be103c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "y = df['price'].values.astype(np.float64)\n",
    "X = df.drop('price', axis=1).values.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59718de7",
   "metadata": {},
   "source": [
    "# Min-Max Scaling\n",
    "Scale the features to a range of [0,1] using Min-Max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d67f76d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Min-Max scaling for features\n",
    "X_min = X.min(axis=0)\n",
    "X_max = X.max(axis=0)\n",
    "X_minmax = (X - X_min) / (X_max - X_min)\n",
    "\n",
    "# Apply Min-Max scaling for target\n",
    "y_min = y.min()\n",
    "y_max = y.max()\n",
    "y_minmax = (y - y_min) / (y_max - y_min)\n",
    "\n",
    "# Add bias term\n",
    "X_minmax = np.c_[np.ones(X_minmax.shape[0]), X_minmax]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dffa09",
   "metadata": {},
   "source": [
    "# Standard Scaling\n",
    "Scale the features using standardization (mean=0, std=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99c70e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Standard scaling for features\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = np.std(X, axis=0)  # Using numpy's std function directly\n",
    "X_standard = (X - X_mean) / X_std\n",
    "\n",
    "# Apply Standard scaling for target\n",
    "y_mean = y.mean()\n",
    "y_std = np.std(y)\n",
    "y_standard = (y - y_mean) / y_std\n",
    "\n",
    "# Add bias term\n",
    "X_standard = np.c_[np.ones(X_standard.shape[0]), X_standard]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632c03f4",
   "metadata": {},
   "source": [
    "# Outlier Removal using Z-Score\n",
    "We use the z-score method to remove outliers from our dataset:\n",
    "- Calculate z-scores for each feature\n",
    "- Remove data points where any feature has |z-score| > 3\n",
    "- This assumes the data follows a normal distribution\n",
    "- Points with z-score > 3 are considered outliers as they lie beyond 3 standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a24403c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-scores shape: (545, 14)\n",
      "Number of outliers removed: 42\n",
      "Cleaned X shape: (503, 15)\n",
      "Cleaned y shape: (503,)\n"
     ]
    }
   ],
   "source": [
    "# Calculate z-scores for features\n",
    "z_scores = np.abs((X - X_mean) / X_std)\n",
    "print(f\"Z-scores shape: {z_scores.shape}\")\n",
    "\n",
    "# Remove outliers (points with z-score > 3)\n",
    "non_outliers_mask = (z_scores < 3).all(axis=1)\n",
    "print(f\"Number of outliers removed: {np.sum(~non_outliers_mask)}\")\n",
    "\n",
    "# Apply outlier removal to both scaled datasets and their respective scaled targets\n",
    "X_cleaned_minmax = X_minmax[non_outliers_mask]\n",
    "X_cleaned_standard = X_standard[non_outliers_mask]\n",
    "y_cleaned_minmax = y_minmax[non_outliers_mask]\n",
    "y_cleaned_standard = y_standard[non_outliers_mask]\n",
    "\n",
    "print(f\"Cleaned X shape: {X_cleaned_minmax.shape}\")\n",
    "print(f\"Cleaned y shape: {y_cleaned_minmax.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749143ca",
   "metadata": {},
   "source": [
    "# Model Training and Comparison\n",
    "We use batch gradient descent to train two linear regression models:\n",
    "1. One with Min-Max scaled features\n",
    "2. One with Standardized features\n",
    "\n",
    "The comparison of Mean Squared Error (MSE) between the two models will help us understand which scaling technique works better for this specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6b4932cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after Min-Max Scaling: [0.07613784 0.03280089 0.0388571  0.02189749 0.04649454 0.07351189\n",
      " 0.02969311 0.03184998 0.         0.06536849 0.03548633 0.04115215\n",
      " 0.03651831 0.03603719 0.00358233]\n",
      "Weights after Standard Scaling: [-0.02373423  0.24418918  0.07785229  0.21256192  0.19073316  0.08451274\n",
      "  0.09000183  0.05489992  0.00520407  0.21606252  0.12500566  0.14805633\n",
      "  0.04163747  0.03194155 -0.07236797]\n",
      "MSE after Min-Max Scaling (scaled values): 0.0121252\n",
      "MSE after Standard Scaling (scaled values): 0.2976820\n"
     ]
    }
   ],
   "source": [
    "def batch_gradient_descent(x, y, lr=0.01, epochs=100):\n",
    "    weights = np.zeros(x.shape[1])\n",
    "    for epoch in range(epochs):\n",
    "        predictions = x @ weights\n",
    "        errors = predictions - y\n",
    "        gradient = (2 / len(y)) * x.T @ errors\n",
    "        weights -= lr * gradient\n",
    "        \n",
    "    return weights\n",
    "\n",
    "# Train the models with scaled targets\n",
    "weights1 = batch_gradient_descent(X_cleaned_minmax, y_cleaned_minmax)\n",
    "weights2 = batch_gradient_descent(X_cleaned_standard, y_cleaned_standard)\n",
    "\n",
    "# Predict\n",
    "y_pred_minmax = X_cleaned_minmax @ weights1\n",
    "y_pred_standard = X_cleaned_standard @ weights2\n",
    "\n",
    "# Calculate MSE on scaled values\n",
    "mse_minmax_scaled = np.mean((y_cleaned_minmax - y_pred_minmax) ** 2)\n",
    "mse_standard_scaled = np.mean((y_cleaned_standard - y_pred_standard) ** 2)\n",
    "\n",
    "# Convert predictions back to original scale for interpretation\n",
    "y_pred_minmax_original = y_pred_minmax * (y_max - y_min) + y_min\n",
    "y_pred_standard_original = y_pred_standard * y_std + y_mean\n",
    "\n",
    "# Output results\n",
    "print(\"Weights after Min-Max Scaling:\", weights1)\n",
    "print(\"Weights after Standard Scaling:\", weights2)\n",
    "print(f\"MSE after Min-Max Scaling (scaled values): {mse_minmax_scaled:.7f}\")\n",
    "print(f\"MSE after Standard Scaling (scaled values): {mse_standard_scaled:.7f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
