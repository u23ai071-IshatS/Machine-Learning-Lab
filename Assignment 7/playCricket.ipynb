{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb5de348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log2\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5952f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(target_col):\n",
    "    elements, counts = np.unique(target_col, return_counts=True)\n",
    "    entropy_val = -np.sum([(counts[i]/np.sum(counts)) * log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
    "    return entropy_val\n",
    "\n",
    "def info_gain(data, split_attribute, target_attribute):\n",
    "    total_entropy = entropy(data[target_attribute])\n",
    "    vals, counts = np.unique(data[split_attribute], return_counts=True)\n",
    "    weighted_entropy = np.sum([(counts[i]/np.sum(counts)) * entropy(data[data[split_attribute] == vals[i]][target_attribute]) for i in range(len(vals))])\n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "def split_info(data, split_attribute):\n",
    "    vals, counts = np.unique(data[split_attribute], return_counts=True)\n",
    "    return -np.sum([(counts[i]/np.sum(counts)) * log2(counts[i]/np.sum(counts)) for i in range(len(vals))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e28efd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(data, original_data, features, target_attribute, parent_class=None):\n",
    "    # If all target values have same label\n",
    "    if len(np.unique(data[target_attribute])) <= 1:\n",
    "        return np.unique(data[target_attribute])[0]\n",
    "    # If dataset is empty\n",
    "    elif len(data) == 0:\n",
    "        return np.unique(original_data[target_attribute])[np.argmax(np.unique(original_data[target_attribute], return_counts=True)[1])]\n",
    "    # If no more features, return majority\n",
    "    elif len(features) == 0:\n",
    "        return parent_class\n",
    "    else:\n",
    "        parent_class = np.unique(data[target_attribute])[np.argmax(np.unique(data[target_attribute], return_counts=True)[1])]\n",
    "        gains = [info_gain(data, feature, target_attribute) for feature in features]\n",
    "        best_feature = features[np.argmax(gains)]\n",
    "        tree = {best_feature: {}}\n",
    "        for value in np.unique(data[best_feature]):\n",
    "            sub_data = data[data[best_feature] == value]\n",
    "            sub_features = [f for f in features if f != best_feature]\n",
    "            subtree = id3(sub_data, data, sub_features, target_attribute, parent_class)\n",
    "            tree[best_feature][value] = subtree\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a785012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c45(data, original_data, features, target_attribute, parent_class=None):\n",
    "    if len(np.unique(data[target_attribute])) <= 1:\n",
    "        return np.unique(data[target_attribute])[0]\n",
    "    elif len(data) == 0:\n",
    "        return np.unique(original_data[target_attribute])[np.argmax(np.unique(original_data[target_attribute], return_counts=True)[1])]\n",
    "    elif len(features) == 0:\n",
    "        return parent_class\n",
    "    else:\n",
    "        parent_class = np.unique(data[target_attribute])[np.argmax(np.unique(data[target_attribute], return_counts=True)[1])]\n",
    "        info_gains = []\n",
    "        for feature in features:\n",
    "            ig = info_gain(data, feature, target_attribute)\n",
    "            si = split_info(data, feature)\n",
    "            gain_ratio = ig / si if si != 0 else 0\n",
    "            info_gains.append(gain_ratio)\n",
    "        best_feature = features[np.argmax(info_gains)]\n",
    "        tree = {best_feature: {}}\n",
    "        for value in np.unique(data[best_feature]):\n",
    "            sub_data = data[data[best_feature] == value]\n",
    "            sub_features = [f for f in features if f != best_feature]\n",
    "            subtree = c45(sub_data, data, sub_features, target_attribute, parent_class)\n",
    "            tree[best_feature][value] = subtree\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "107ecf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, sample):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    feature = list(tree.keys())[0]\n",
    "    if sample[feature] in tree[feature]:\n",
    "        return predict(tree[feature][sample[feature]], sample)\n",
    "    else:\n",
    "        # unseen attribute value â†’ majority guess\n",
    "        return list(Counter([v for v in tree[feature].values() if not isinstance(v, dict)]).keys())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e63817d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/playCricket.csv')\n",
    "\n",
    "# Convert continuous values to boolean (threshold)\n",
    "# Here assume Temperature and Humidity are continuous (Hot/Mild/Cool, High/Normal)\n",
    "# Convert them into binary features based on logical thresholds\n",
    "df['Temperature'] = df['Temperature'].map({'Hot':1, 'Mild':0, 'Cool':0})\n",
    "df['Humidity'] = df['Humidity'].map({'High':1, 'Normal':0})\n",
    "\n",
    "# Encode categorical columns except target\n",
    "df['Outlook'] = df['Outlook'].astype('category')\n",
    "df['Wind'] = df['Wind'].astype('category')\n",
    "df['PlayCricket'] = df['PlayCricket'].astype('category')\n",
    "\n",
    "# Drop 'Day' column (not a feature)\n",
    "df.drop(columns=['Day'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c30b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "X = df.drop('PlayCricket', axis=1)\n",
    "y = df['PlayCricket']\n",
    "\n",
    "id3_metrics, c45_metrics = [], []\n",
    "\n",
    "for train_index, test_index in kf.split(df):\n",
    "    train_data, test_data = df.iloc[train_index], df.iloc[test_index]\n",
    "    \n",
    "    features = list(X.columns)\n",
    "    \n",
    "    id3_tree = id3(train_data, train_data, features, 'PlayCricket')\n",
    "    c45_tree = c45(train_data, train_data, features, 'PlayCricket')\n",
    "    \n",
    "    y_true = test_data['PlayCricket'].values\n",
    "    y_pred_id3 = [predict(id3_tree, row) for _, row in test_data.iterrows()]\n",
    "    y_pred_c45 = [predict(c45_tree, row) for _, row in test_data.iterrows()]\n",
    "    \n",
    "    # Compute metrics\n",
    "    for algo, pred, metric_list in [('ID3', y_pred_id3, id3_metrics), ('C4.5', y_pred_c45, c45_metrics)]:\n",
    "        acc = accuracy_score(y_true, pred)\n",
    "        prec = precision_score(y_true, pred, pos_label='Yes', zero_division=0)\n",
    "        rec = recall_score(y_true, pred, pos_label='Yes')\n",
    "        f1 = f1_score(y_true, pred, pos_label='Yes', zero_division=0)\n",
    "        metric_list.append([acc, prec, rec, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a2fc1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ID3 Decision Tree ===\n",
      "Accuracy: 0.933, Precision: 0.933, Recall: 1.000, F1: 0.960\n",
      "\n",
      "=== C4.5 Decision Tree ===\n",
      "Accuracy: 0.600, Precision: 0.667, Recall: 0.700, F1: 0.653\n",
      "\n",
      "Sample ID3 Tree:\n",
      "{'Outlook': {'Overcast': 'Yes',\n",
      "             'Rain': {'Wind': {'Strong': 'No', 'Weak': 'Yes'}},\n",
      "             'Sunny': {'Humidity': {np.int64(0): 'Yes', np.int64(1): 'No'}}}}\n",
      "\n",
      "Sample C4.5 Tree:\n",
      "{'Humidity': {np.int64(0): {'Wind': {'Strong': {'Outlook': {'Rain': 'No',\n",
      "                                                            'Sunny': 'Yes'}},\n",
      "                                     'Weak': 'Yes'}},\n",
      "              np.int64(1): {'Outlook': {'Overcast': 'Yes',\n",
      "                                        'Rain': 'No',\n",
      "                                        'Sunny': 'No'}}}}\n"
     ]
    }
   ],
   "source": [
    "def avg_metrics(metrics):\n",
    "    return np.mean(metrics, axis=0)\n",
    "\n",
    "id3_avg = avg_metrics(id3_metrics)\n",
    "c45_avg = avg_metrics(c45_metrics)\n",
    "\n",
    "print(\"=== ID3 Decision Tree ===\")\n",
    "print(f\"Accuracy: {id3_avg[0]:.3f}, Precision: {id3_avg[1]:.3f}, Recall: {id3_avg[2]:.3f}, F1: {id3_avg[3]:.3f}\")\n",
    "print(\"\\n=== C4.5 Decision Tree ===\")\n",
    "print(f\"Accuracy: {c45_avg[0]:.3f}, Precision: {c45_avg[1]:.3f}, Recall: {c45_avg[2]:.3f}, F1: {c45_avg[3]:.3f}\")\n",
    "\n",
    "print(\"\\nSample ID3 Tree:\")\n",
    "pprint(id3_tree)\n",
    "print(\"\\nSample C4.5 Tree:\")\n",
    "pprint(c45_tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
